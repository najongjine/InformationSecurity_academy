# -*- coding: utf-8 -*-
"""cnn_EfficientNetB0_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G7eIMYPSqiSvpPKb0l9r2CoD5DxyUBXq
"""

import tensorflow as tf

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input

from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.optimizers import Adam
import numpy as np
import os
import json
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

# seed ê³ ì •
seed = 15
np.random.seed(seed)
tf.random.set_seed(seed)

# ì„¤ì •ê°’
BATCH_SIZE = 16
EPOCHS = 50
IMG_HEIGHT = 224
IMG_WIDTH = 224

# ë°ì´í„° í´ë” ê²½ë¡œ (ë„ˆê°€ ì¤€ë¹„í•œ í´ë” êµ¬ì¡°ì— ë§ì¶°ì„œ)
base_dir = '/content/drive/MyDrive/dataset/cat_dog_horse'  # ì§ì ‘ ì¤€ë¹„í•œ í´ë”ëª…
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

###################### ì¸ê³µì§€ëŠ¥ì´ ì›í•˜ëŠ” í˜•íƒœë¡œ ì´ë¯¸ì§€ ê°€ê³µ ###############################
train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    label_mode='categorical',
    batch_size=BATCH_SIZE,
    image_size=(IMG_HEIGHT, IMG_WIDTH), # ì„ì‹œ í¬ê¸°
    shuffle=True
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    validation_dir,
    label_mode='categorical',
    batch_size=BATCH_SIZE,
    image_size=(IMG_HEIGHT, IMG_WIDTH),
    shuffle=False
)


def augment(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, max_delta=0.2)
    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)
    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)
    image = tf.image.random_hue(image, max_delta=0.05)
    return image, label


def resize_pad_preprocess(image, label):
    image = tf.image.resize_with_pad(image, IMG_HEIGHT, IMG_WIDTH)
    image = preprocess_input(image)  # EfficientNetìš© ì „ì²˜ë¦¬
    return image, label

# class_names ì €ì¥
class_list = train_ds.class_names


# train: ì¦ê°• + resize/pad + ì „ì²˜ë¦¬
train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)
train_ds = train_ds.map(resize_pad_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
train_ds = train_ds.prefetch(tf.data.AUTOTUNE)

# validation: resize/pad + ì „ì²˜ë¦¬ë§Œ
val_ds = val_ds.map(resize_pad_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
val_ds = val_ds.prefetch(tf.data.AUTOTUNE)



###################### ì¸ê³µì§€ëŠ¥ì´ ì›í•˜ëŠ” í˜•íƒœë¡œ ì´ë¯¸ì§€ ê°€ê³µ  END ###############################


####################### EfficientNetB0 ëª¨ë¸ì„ ê°€ì ¸ì˜¨ ë‹¤ìŒ íŒŒì¸íŠœë‹ ëª¨ë“œë¡œ ë³€ê²½    #####################
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))

# ì „ì´í•™ìŠµ
for layer in base_model.layers:
    layer.trainable = False

# ë¯¸ì„¸ì¡°ì •
#for layer in base_model.layers[:-20]:  # ë§ˆì§€ë§‰ 20ê°œ ë ˆì´ì–´ë§Œ ì—´ê¸°
#    layer.trainable = False


# 3. ë¶„ë¥˜ê¸°ì¸µ (ì¶œë ¥ì¸µ)
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.5)(x)
output_layer = Dense(3, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output_layer)
model.summary()

####################### EfficientNetB0 ëª¨ë¸ì„ ê°€ì ¸ì˜¨ ë‹¤ìŒ íŒŒì¸íŠœë‹ ëª¨ë“œë¡œ ë³€ê²½  END  #####################




#################### í•™ìŠµ #######################
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

loss_fn = CategoricalCrossentropy(label_smoothing=0.1)

model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss=loss_fn,
    metrics=['accuracy']
)

# restore_best_weights=True ëœ» : ê²€ì¦ ì†ì‹¤(val_loss)ì´ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    train_ds,
    epochs=EPOCHS,
    validation_data=val_ds,
    callbacks=[early_stop]
)
#################### í•™ìŠµ #######################

import matplotlib.pyplot as plt

# ì •í™•ë„ ê·¸ë˜í”„
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# ì†ì‹¤(loss) ê·¸ë˜í”„
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

from google.colab import drive
drive.mount('/content/drive')



################ ëª¨ë¸ ë‹¤ í›ˆë ¨ ì‹œí‚¨ê±° ì €ì¥ #####################
import os
import json

# ì €ì¥í•  ê²½ë¡œ
save_dir = '/content/drive/MyDrive/my_models/tensorflow_keras'
save_model_path = os.path.join(save_dir, 'EfficientNetB0.h5')
save_label_path = os.path.join(save_dir, 'EfficientNetB0.json')

# í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë§Œë“¤ê¸°
if not os.path.exists(save_dir):
    os.makedirs(save_dir)
    print(f"ğŸ“‚ í´ë” ìƒì„±ë¨: {save_dir}")

# ëª¨ë¸ ì €ì¥
model.save(save_model_path)
print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_model_path}")
# âœ… í´ë˜ìŠ¤ ì´ë¦„ ì €ì¥
# í´ë” ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ ìë™ ì¶”ì¶œëœ í´ë˜ìŠ¤ ìˆœì„œ
with open(save_label_path, 'w') as f:
    json.dump(class_list, f)
print(f"âœ… í´ë˜ìŠ¤ ì´ë¦„ ì €ì¥ ì™„ë£Œ: {save_label_path}")
################ ëª¨ë¸ ë‹¤ í›ˆë ¨ ì‹œí‚¨ê±° ì €ì¥ END #####################