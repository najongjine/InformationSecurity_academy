# -*- coding: utf-8 -*-
"""cnn_EfficientNetB0_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G7eIMYPSqiSvpPKb0l9r2CoD5DxyUBXq
"""

import tensorflow as tf

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input

from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.optimizers import Adam
import numpy as np
import os
import json
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

# seed 고정
seed = 15
np.random.seed(seed)
tf.random.set_seed(seed)

# 설정값
BATCH_SIZE = 16
EPOCHS = 50
IMG_HEIGHT = 224
IMG_WIDTH = 224

# 데이터 폴더 경로 (너가 준비한 폴더 구조에 맞춰서)
base_dir = '/content/drive/MyDrive/dataset/cat_dog_horse'  # 직접 준비한 폴더명
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

###################### 인공지능이 원하는 형태로 이미지 가공 ###############################
train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    label_mode='categorical',
    batch_size=BATCH_SIZE,
    image_size=(IMG_HEIGHT, IMG_WIDTH), # 임시 크기
    shuffle=True
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    validation_dir,
    label_mode='categorical',
    batch_size=BATCH_SIZE,
    image_size=(IMG_HEIGHT, IMG_WIDTH),
    shuffle=False
)


def augment(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, max_delta=0.2)
    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)
    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)
    image = tf.image.random_hue(image, max_delta=0.05)
    return image, label


def resize_pad_preprocess(image, label):
    image = tf.image.resize_with_pad(image, IMG_HEIGHT, IMG_WIDTH)
    image = preprocess_input(image)  # EfficientNet용 전처리
    return image, label

# class_names 저장
class_list = train_ds.class_names


# train: 증강 + resize/pad + 전처리
train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)
train_ds = train_ds.map(resize_pad_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
train_ds = train_ds.prefetch(tf.data.AUTOTUNE)

# validation: resize/pad + 전처리만
val_ds = val_ds.map(resize_pad_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
val_ds = val_ds.prefetch(tf.data.AUTOTUNE)



###################### 인공지능이 원하는 형태로 이미지 가공  END ###############################


####################### EfficientNetB0 모델을 가져온 다음 파인튜닝 모드로 변경    #####################
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))

# 전이학습
for layer in base_model.layers:
    layer.trainable = False

# 미세조정
#for layer in base_model.layers[:-20]:  # 마지막 20개 레이어만 열기
#    layer.trainable = False


# 3. 분류기층 (출력층)
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.5)(x)
output_layer = Dense(3, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output_layer)
model.summary()

####################### EfficientNetB0 모델을 가져온 다음 파인튜닝 모드로 변경  END  #####################




#################### 학습 #######################
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

loss_fn = CategoricalCrossentropy(label_smoothing=0.1)

model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss=loss_fn,
    metrics=['accuracy']
)

# restore_best_weights=True 뜻 : 검증 손실(val_loss)이 개선되지 않으면 조기 종료
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    train_ds,
    epochs=EPOCHS,
    validation_data=val_ds,
    callbacks=[early_stop]
)
#################### 학습 #######################

import matplotlib.pyplot as plt

# 정확도 그래프
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# 손실(loss) 그래프
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

from google.colab import drive
drive.mount('/content/drive')



################ 모델 다 훈련 시킨거 저장 #####################
import os
import json

# 저장할 경로
save_dir = '/content/drive/MyDrive/my_models/tensorflow_keras'
save_model_path = os.path.join(save_dir, 'EfficientNetB0.h5')
save_label_path = os.path.join(save_dir, 'EfficientNetB0.json')

# 폴더가 없으면 자동으로 만들기
if not os.path.exists(save_dir):
    os.makedirs(save_dir)
    print(f"📂 폴더 생성됨: {save_dir}")

# 모델 저장
model.save(save_model_path)
print(f"✅ 모델 저장 완료: {save_model_path}")
# ✅ 클래스 이름 저장
# 폴더 이름 기반으로 자동 추출된 클래스 순서
with open(save_label_path, 'w') as f:
    json.dump(class_list, f)
print(f"✅ 클래스 이름 저장 완료: {save_label_path}")
################ 모델 다 훈련 시킨거 저장 END #####################