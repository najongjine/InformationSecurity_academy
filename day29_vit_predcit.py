"""
!pip install -q transformers timm
"""
# 2. Colabì—ì„œ ì´ë¯¸ì§€ ì—…ë¡œë“œ
from google.colab import files
from PIL import Image
import torch
import numpy as np
from transformers import Trainer, AutoImageProcessor, ViTForImageClassification
import torch.nn.functional as F

from google.colab import drive
drive.mount('/content/drive')

# ì—…ë¡œë“œ ë²„íŠ¼ìœ¼ë¡œ ì´ë¯¸ì§€ ì„ íƒ
uploaded = files.upload()
image_path = list(uploaded.keys())[0]
image = Image.open(image_path).convert("RGB")

# 3. ëª¨ë¸ê³¼ Processor ë¶ˆëŸ¬ì˜¤ê¸°
model_path = "/content/drive/MyDrive/my_models/vit_cat_dog_horse1"
model = ViTForImageClassification.from_pretrained(model_path)
processor = AutoImageProcessor.from_pretrained(model_path)

# 4. ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬ (Trainerê°€ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜)
inputs = processor(images=image, return_tensors="pt")

# 5. Trainer ì‚¬ìš©í•´ì„œ ì˜ˆì¸¡
trainer = Trainer(model=model)

# Trainer.predict()ëŠ” Dataset í˜•ì‹ë§Œ ë°›ìŒ â†’ ë‹¨ì¼ ì˜ˆì¸¡ìš© Dataset ìƒì„±
class SingleImageDataset(torch.utils.data.Dataset):
    def __init__(self, inputs):
        self.inputs = inputs

    def __getitem__(self, idx):
        return {k: v.squeeze(0) for k, v in self.inputs.items()}

    def __len__(self):
        return 1

dataset = SingleImageDataset(inputs)
output = trainer.predict(dataset)

# 6. ê²°ê³¼ í•´ì„
logits = output.predictions
probs = F.softmax(torch.tensor(logits), dim=-1)
max_prob, pred_idx = torch.max(probs, dim=-1)

predicted_label = model.config.id2label[pred_idx.item()]
confidence = max_prob.item()

print(f"\nâœ… ì˜ˆì¸¡ ê²°ê³¼: {predicted_label}")
print(f"ğŸ” ì‹ ë¢°ë„: {confidence:.4f}")

# 7. ì•Œ ìˆ˜ ì—†ìŒ ì²˜ë¦¬
threshold = 0.61
if confidence < threshold:
    print("âŒ Result: ì•Œ ìˆ˜ ì—†ìŒ (ì‹ ë¢°ë„ ë‚®ìŒ)")
else:
    print(f"âœ… Result: {predicted_label}")