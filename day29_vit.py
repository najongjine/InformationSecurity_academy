""" 
1. ë°ì´í„° ì¤€ë¹„
2. ëª¨ë¸ ì¤€ë¹„
3. ë°ì´í„°ë¥¼ ëª¨ë¸ì´ ì›í•˜ëŠ” íƒ€ì…ìœ¼ë¡œ ë°”ê¿”ì£¼ê¸°
4. ëª¨ë¸ì„ íŒŒì¸íŠœë‹ ëª¨ë“œë¡œ ë³€ê²½í•˜ê¸°
5. íŒŒì¸íŠœë‹ ì‹œì‘

wandb.ai apikey: cd3a959f4d15312bbe8f8fda20bd300f6f763a20

!pip install - U transformers datasets torchvision
pip install - U datasets huggingface_hub fsspec
"""




from transformers import ViTForImageClassification, AutoImageProcessor, TrainingArguments, Trainer
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import numpy as np
import os
from sklearn.metrics import accuracy_score

from google.colab import drive
drive.mount('/content/drive')

# ê²½ë¡œ ì„¤ì •
train_dir = "/content/drive/MyDrive/dataset/corn_leaf/train"
val_dir = "/content/drive/MyDrive/dataset/corn_leaf/validation"


# ë°ì´í„°ë¥¼ ëª¨ë¸ì´ ì›í•˜ëŠ” íƒ€ì…ìœ¼ë¡œ ë°”ê¿”ì£¼ê¸°
BATCH_SIZE = 8
EPOCHS = 10
IMG_HEIGHT = 384
IMG_WIDTH = 384

# âœ… Trainerê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” ë˜í¼ í´ë˜ìŠ¤
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, processor):
        self.dataset = dataset
        self.processor = processor

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        img, label = self.dataset[idx]
        encoding = self.processor(images=img, return_tensors="pt")
        return {
            "pixel_values": encoding["pixel_values"].squeeze(),
            "labels": label
        }

# ì „ì²˜ë¦¬ê¸°
checkpoint = "facebook/deit-base-distilled-patch16-384"
processor = AutoImageProcessor.from_pretrained(checkpoint)

from torchvision import datasets, transforms

transform = transforms.Compose([
    transforms.Resize((IMG_HEIGHT,IMG_WIDTH)),
    #transforms.CenterCrop(IMG_WIDTH), # ratio ìœ ì§€ + center crop
    transforms.Lambda(lambda img: transforms.functional.pad( # ì „ì²´ ratio ìœ ì§€
        img,
        padding=(
            (IMG_WIDTH - img.size[0]) // 2,  # left padding
            (IMG_WIDTH - img.size[1]) // 2,  # top padding
            (IMG_WIDTH - img.size[0] + 1) // 2,  # right padding
            (IMG_WIDTH - img.size[1] + 1) // 2   # bottom padding
        ),
        fill=0
    )),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    #transforms.ToTensor(),
    #transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))
])

train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)
val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)


train_ds = CustomDataset(train_dataset, processor)
val_ds = CustomDataset(val_dataset, processor)

# ë°ì´í„°ë¥¼ ëª¨ë¸ì´ ì›í•˜ëŠ” íƒ€ì…ìœ¼ë¡œ ë°”ê¿”ì£¼ê¸° END



# ëª¨ë¸ì„ íŒŒì¸íŠœë‹ ëª¨ë“œë¡œ ë³€ê²½í•˜ê¸°
id2label = {i: label for i, label in enumerate(train_dataset.classes)}
label2id = {label: i for i, label in enumerate(train_dataset.classes)}

checkpoint = "facebook/deit-base-distilled-patch16-384"
model = ViTForImageClassification.from_pretrained(
    checkpoint,
    num_labels=len(train_dataset.classes),
    id2label=id2label,
    label2id=label2id
)

finetune_whole_model = False  # â† Trueë©´ ì•ë¶€ë¶„ê¹Œì§€ í›ˆë ¨, Falseë©´ ì¶œë ¥ì¸µë§Œ

if not finetune_whole_model:
    for name, param in model.named_parameters():
        if "classifier" in name:
            param.requires_grad = True
        else:
            param.requires_grad = False
# ëª¨ë¸ì„ íŒŒì¸íŠœë‹ ëª¨ë“œë¡œ ë³€ê²½í•˜ê¸° END


# í›ˆë ¨í•˜ê¸°
# í‰ê°€ ì§€í‘œ
def compute_metrics(p):
    preds = np.argmax(p.predictions, axis=1)
    labels = p.label_ids
    acc = accuracy_score(labels, preds)
    return {"accuracy": acc}

# í›ˆë ¨ ì¸ì
training_args = TrainingArguments(
    output_dir="./vit-cornleaf",
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE,
    num_train_epochs=EPOCHS,
    eval_strategy="epoch",
    save_strategy="epoch",
    logging_dir="./logs",
    logging_steps=10,
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    greater_is_better=True,
    push_to_hub=False,
    report_to="none"
)

# Trainer êµ¬ì„±
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_ds,
    eval_dataset=val_ds,
    compute_metrics=compute_metrics
)

trainer.train()

# ì €ì¥
# í›ˆë ¨í•˜ê¸° END


# í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë§Œë“¤ê¸°
save_dir="/content/drive/MyDrive/my_models/vit/vit_deit384_cornleaf"
if not os.path.exists(save_dir):
    os.makedirs(save_dir)
    print(f"ğŸ“‚ í´ë” ìƒì„±ë¨: {save_dir}")

# ì €ì¥
model.save_pretrained(save_dir)
processor.save_pretrained(save_dir)
# í›ˆë ¨í•˜ê¸° END


# ê·¸ë˜í”„
import matplotlib.pyplot as plt
import pandas as pd

# trainer.train() ì‹¤í–‰ í›„
train_output = trainer.train()

# log_historyì—ì„œ pandas DataFrameìœ¼ë¡œ ë³€í™˜
logs = pd.DataFrame(trainer.state.log_history)

# train/val lossì™€ accuracyë§Œ í•„í„°ë§
train_loss = logs[logs['loss'].notnull()][['epoch', 'loss']]
eval_logs = logs[logs['eval_loss'].notnull()][['epoch', 'eval_loss', 'eval_accuracy']]

# âœ… ì†ì‹¤(loss) ê·¸ë˜í”„
plt.figure(figsize=(8, 5))
plt.plot(train_loss['epoch'], train_loss['loss'], label='Train Loss')
plt.plot(eval_logs['epoch'], eval_logs['eval_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.grid()
plt.show()

# âœ… ì •í™•ë„(accuracy) ê·¸ë˜í”„
plt.figure(figsize=(8, 5))
plt.plot(eval_logs['epoch'], eval_logs['eval_accuracy'], marker='o', label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Validation Accuracy')
plt.legend()
plt.grid()
plt.show()
# ê·¸ë˜í”„ END